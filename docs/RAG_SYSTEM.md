# üß† RAG (Retrieval-Augmented Generation) System

## Overview

The Lab68 Dev Platform now includes an advanced **RAG (Retrieval-Augmented Generation)** system that enhances your AI chat with context from the platform's documentation, features, and codebase. Instead of training a completely new model, RAG retrieves relevant information and provides it as context to the AI, making responses more accurate and platform-specific.

## üéØ What is RAG?

**RAG combines two powerful capabilities:**

1. **Retrieval**: Semantic search through your knowledge base to find relevant documents
2. **Generation**: AI model (Ollama) uses the retrieved context to generate informed responses

**Benefits:**

- ‚úÖ No expensive model training required
- ‚úÖ Responses based on your actual documentation
- ‚úÖ Easy to update (just re-index new content)
- ‚úÖ Works with existing Ollama models
- ‚úÖ Privacy-first (all data stays in your Supabase)

## üèóÔ∏è Architecture

```
User Question
     ‚Üì
1. Generate Embedding (384D vector)
     ‚Üì
2. Search Supabase pgvector (cosine similarity)
     ‚Üì
3. Retrieve Top 3-5 Relevant Documents
     ‚Üì
4. Build Context + User Question
     ‚Üì
5. Send to Ollama AI
     ‚Üì
6. AI Generates Informed Response
```

### Components

- **Embedding Model**: `Xenova/all-MiniLM-L6-v2` (384 dimensions, runs in browser/Node.js)
- **Vector Database**: Supabase pgvector extension
- **RAG Service**: `lib/services/rag-service.ts`
- **Knowledge Indexer**: `scripts/index-knowledge.js`
- **Chat API**: Enhanced with RAG context retrieval

## üöÄ Setup Instructions

### Step 1: Enable pgvector in Supabase

1. Go to your Supabase project dashboard
2. Navigate to **SQL Editor**
3. Run the schema file:

```sql
-- Copy and paste the contents of: lib/database/rag-schema.sql
```

This creates:

- `knowledge_base` table with vector embeddings
- `match_documents()` function for similarity search
- Indexes for fast retrieval

### Step 2: Verify Installation

Check your terminal - dependencies should already be installed:

- ‚úÖ `@xenova/transformers` - For embeddings
- ‚úÖ `chromadb` - Alternative local vector store (optional)

### Step 3: Index Your Knowledge Base

Run the indexer to populate the RAG system:

```powershell
# Index all documentation and features
node scripts/index-knowledge.js

# Index only documentation
node scripts/index-knowledge.js --category=docs

# Clear and re-index
node scripts/index-knowledge.js --clear
```

**What gets indexed:**

- All markdown files in `/docs` directory
- Platform features and capabilities
- Technical stack information

### Step 4: Test RAG in AI Chat

1. Open the AI Tools page: `/dashboard/ai-tools`
2. Ask platform-specific questions like:
   - "How do I set up Ollama?"
   - "What features does this platform have?"
   - "How does the resume builder work?"
   - "What is the technical stack?"

3. The AI should now respond with context from your documentation!

## üìä RAG Service API

### Basic Usage

```typescript
import { ragService } from '@/lib/services/rag-service'

// Search for relevant documents
const results = await ragService.searchDocuments('How to deploy?', {
  limit: 5,
  threshold: 0.7,
  category: 'documentation'
})

// Get formatted context for AI
const context = await ragService.getContextForQuery('Setup guide')

// Add a new document
await ragService.addDocument({
  content: 'Your documentation content here',
  category: 'documentation',
  source: 'docs/new-feature.md',
  title: 'New Feature Guide'
})

// Add multiple documents
await ragService.addDocuments([
  { content: 'Doc 1...', title: 'Guide 1' },
  { content: 'Doc 2...', title: 'Guide 2' }
])
```

### Search Options

```typescript
interface SearchOptions {
  limit?: number        // Max results to return (default: 5)
  threshold?: number    // Similarity threshold 0-1 (default: 0.7)
  category?: string     // Filter by category (e.g., 'documentation', 'feature')
}
```

### Document Categories

- `documentation` - Markdown files from /docs
- `feature` - Platform features and capabilities
- `technical` - Technical stack and architecture
- `api` - API documentation
- `code` - Code snippets and examples

## üîß Configuration

### Environment Variables

Add to your `.env.local`:

```env
# Supabase (required for RAG)
NEXT_PUBLIC_SUPABASE_URL=your-supabase-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key

# Ollama (existing)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:7b
```

### Embedding Model

The system uses `all-MiniLM-L6-v2` which:

- Produces 384-dimensional vectors
- Fast inference (< 50ms per document)
- Good quality for semantic search
- Works in browser and Node.js

**To change the model**, edit `lib/services/rag-service.ts`:

```typescript
this.embeddingPipeline = await pipeline(
  'feature-extraction',
  'Xenova/all-MiniLM-L6-v2'  // Change this
)
```

### Similarity Threshold

Adjust in chat API or when calling `searchDocuments()`:

```typescript
// More strict (0.8-0.9) - Only highly relevant results
// Balanced (0.7) - Good default
// More lenient (0.5-0.6) - More results, less relevant
```

## üìà Performance

### Embedding Generation

- **Speed**: ~30-50ms per query
- **Model**: 80MB (cached after first use)
- **Runs**: Client-side or server-side

### Vector Search

- **Speed**: < 10ms for 1000s of documents
- **Index**: IVFFlat (configurable)
- **Scalability**: Handles 100K+ documents efficiently

## üõ†Ô∏è Advanced Usage

### Custom Document Chunking

Modify `scripts/index-knowledge.js`:

```javascript
const CHUNK_SIZE = 1000      // Characters per chunk
const CHUNK_OVERLAP = 200    // Overlap for context
```

### Adding Code Examples

```typescript
await ragService.addDocument({
  content: `
    // Example: Create a new project
    const project = await createProject({
      name: 'My Project',
      description: 'Project description'
    })
  `,
  category: 'code',
  source: 'examples/projects.ts',
  title: 'Creating a Project',
  metadata: {
    language: 'typescript',
    module: 'projects'
  }
})
```

### Filtering by Category

```typescript
// Only search documentation
const docs = await ragService.searchDocuments('deploy', {
  category: 'documentation'
})

// Only search code examples
const code = await ragService.searchDocuments('create project', {
  category: 'code'
})
```

## üîÑ Updating Knowledge Base

### Re-index After Documentation Changes

```powershell
# Clear old docs and re-index
node scripts/index-knowledge.js --clear --category=documentation
```

### Incremental Updates

```typescript
// Add new documents without clearing
await ragService.addDocument({
  content: 'New feature documentation',
  category: 'documentation',
  source: 'docs/new-feature.md',
  title: 'New Feature'
})
```

### Delete Specific Documents

```typescript
// Get document ID from search results
const results = await ragService.searchDocuments('old feature')
await ragService.deleteDocument(results[0].id)
```

## üé® UI Integration

The RAG system is automatically integrated into the AI chat. To toggle RAG on/off, modify the request:

```typescript
const response = await fetch('/api/chat', {
  method: 'POST',
  body: JSON.stringify({
    message: 'Your question',
    history: chatHistory,
    useRAG: true  // Set to false to disable RAG
  })
})
```

## üêõ Troubleshooting

### "Table knowledge_base does not exist"

- Run the SQL schema in Supabase SQL Editor
- Verify pgvector extension is enabled

### "Failed to initialize embeddings"

- Check internet connection (first download)
- Clear `node_modules/.cache/transformers`
- Restart dev server

### "No documents found"

- Run the indexer: `node scripts/index-knowledge.js`
- Check Supabase table has data
- Verify Supabase credentials in `.env.local`

### RAG returns empty context

- Lower similarity threshold (try 0.5-0.6)
- Increase result limit
- Check if documents exist in that category

## üìö Next Steps

1. **Index More Content**: Add code examples, API docs, FAQs
2. **Fine-tune Retrieval**: Adjust chunk size and similarity thresholds
3. **Add Categories**: Organize content by modules/features
4. **Monitor Quality**: Track which queries get good context
5. **User Feedback**: Add thumbs up/down to improve results

## üîó Related Files

- Schema: `lib/database/rag-schema.sql`
- Service: `lib/services/rag-service.ts`
- Indexer: `scripts/index-knowledge.js`
- Chat API: `app/api/chat/route.ts`
- AI Tools UI: `app/dashboard/ai-tools/page.tsx`

## üí° Tips

- Keep documents focused (500-1500 characters optimal)
- Use clear, descriptive titles
- Include relevant keywords in content
- Update index when documentation changes
- Monitor RAG performance with logging

---

**RAG System Status**: ‚úÖ Ready for Production

Your AI is now powered by your own knowledge base!
